{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **Data Collection Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "* Fetch data from Kaggle and save it as raw data.\n",
    "* Inspect the data and save it under `outputs/datasets/collection`\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* Kaggle JSON file — the authentication token.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Generate Dataset: `outputs/datasets/collection/ai_job_dataset1.csv`\n",
    "\n",
    "## Additional Comments\n",
    "\n",
    "* Dataset: **Global AI Job Market & Salary Trends 2025** by Bisma Sajjad on Kaggle.\n",
    "* 15,000+ synthetic job listings from 50+ countries with 20 features.\n",
    "* In the workplace, data is not pushed to public repositories for security reasons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOGIGS-uz3i2"
   },
   "source": [
    "We need to change the working directory from its current folder to its parent folder.\n",
    "* We access the current directory with `os.getcwd()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\chahi\\\\Desktop\\\\vscode-project\\\\the-ai-salary-index\\\\jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MWW8E7lz3i7"
   },
   "source": [
    "We want to make the parent of the current directory the new current directory.\n",
    "* `os.path.dirname()` gets the parent directory\n",
    "* `os.chdir()` defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TwHsQRWjz3i9",
    "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_xPk_Ijz3i-"
   },
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vz3S-_kjz3jA",
    "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\chahi\\\\Desktop\\\\vscode-project\\\\the-ai-salary-index'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "# Fetch data from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the Kaggle package to fetch data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle==2.0.0\n",
      "  Downloading kaggle-2.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting bleach (from kaggle==2.0.0)\n",
      "  Using cached bleach-6.3.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting kagglesdk<1.0,>=0.1.15 (from kaggle==2.0.0)\n",
      "  Downloading kagglesdk-0.1.15-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\chahi\\desktop\\vscode-project\\the-ai-salary-index\\.venv\\lib\\site-packages (from kaggle==2.0.0) (26.0)\n",
      "Collecting protobuf (from kaggle==2.0.0)\n",
      "  Downloading protobuf-6.33.5-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\chahi\\desktop\\vscode-project\\the-ai-salary-index\\.venv\\lib\\site-packages (from kaggle==2.0.0) (2.9.0.post0)\n",
      "Collecting python-slugify (from kaggle==2.0.0)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting requests (from kaggle==2.0.0)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tqdm (from kaggle==2.0.0)\n",
      "  Downloading tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting urllib3>=1.15.1 (from kaggle==2.0.0)\n",
      "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting webencodings (from bleach->kaggle==2.0.0)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chahi\\desktop\\vscode-project\\the-ai-salary-index\\.venv\\lib\\site-packages (from python-dateutil->kaggle==2.0.0) (1.17.0)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle==2.0.0)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->kaggle==2.0.0)\n",
      "  Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->kaggle==2.0.0)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->kaggle==2.0.0)\n",
      "  Downloading certifi-2026.2.25-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\chahi\\desktop\\vscode-project\\the-ai-salary-index\\.venv\\lib\\site-packages (from tqdm->kaggle==2.0.0) (0.4.6)\n",
      "Downloading kaggle-2.0.0-py3-none-any.whl (75 kB)\n",
      "Downloading kagglesdk-0.1.15-py3-none-any.whl (160 kB)\n",
      "Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Using cached bleach-6.3.0-py3-none-any.whl (164 kB)\n",
      "Downloading protobuf-6.33.5-cp310-abi3-win_amd64.whl (437 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
      "Downloading certifi-2026.2.25-py3-none-any.whl (153 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webencodings, text-unidecode, urllib3, tqdm, python-slugify, protobuf, idna, charset_normalizer, certifi, bleach, requests, kagglesdk, kaggle\n",
      "Successfully installed bleach-6.3.0 certifi-2026.2.25 charset_normalizer-3.4.4 idna-3.11 kaggle-2.0.0 kagglesdk-0.1.15 protobuf-6.33.5 python-slugify-8.0.4 requests-2.32.5 text-unidecode-1.3 tqdm-4.67.3 urllib3-2.6.3 webencodings-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install kaggle==2.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need a `kaggle.json` file (authentication token) in the project root.\n",
    "* Download it from your Kaggle account under **Account → API → Create New API Token**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Kaggle dataset path and the destination folder, then download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/bismasajjad/global-ai-job-market-and-salary-trends-2025\n",
      "License(s): CC0-1.0\n",
      "Downloading global-ai-job-market-and-salary-trends-2025.zip to inputs/datasets/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/1.08M [00:00<?, ?B/s]\n",
      " 93%|█████████▎| 1.00M/1.08M [00:00<00:00, 2.17MB/s]\n",
      "100%|██████████| 1.08M/1.08M [00:00<00:00, 2.13MB/s]\n"
     ]
    }
   ],
   "source": [
    "KaggleDatasetPath = \"bismasajjad/global-ai-job-market-and-salary-trends-2025\"\n",
    "DestinationFolder = \"inputs/datasets/raw\"\n",
    "os.makedirs(DestinationFolder, exist_ok=True)\n",
    "\n",
    "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip the downloaded file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All ZIP files extracted and deleted.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import zipfile\n",
    "\n",
    "# Find all zip files in the folder\n",
    "zip_files = glob.glob(os.path.join(DestinationFolder, \"*.zip\"))\n",
    "\n",
    "# Extract each zip file and then delete it\n",
    "for zip_path in zip_files:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(DestinationFolder)\n",
    "    os.remove(zip_path)\n",
    "\n",
    "# Remove kaggle.json if it exists to avoid exposing credentials\n",
    "kaggle_json = os.path.join(os.getcwd(), \"kaggle.json\")\n",
    "if os.path.exists(kaggle_json):\n",
    "    os.remove(kaggle_json)\n",
    "\n",
    "print(\"All ZIP files extracted and deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m df = pd.read_csv(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDestinationFolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/ai_job_dataset1.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(f\"{DestinationFolder}/ai_job_dataset1.csv\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check data types and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltNetd085qHf"
   },
   "source": [
    "# Push files to Repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If you do not need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKlnIozA4eQO",
    "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "  # create here your folder\n",
    "  # os.makedirs(name='')\n",
    "except Exception as e:\n",
    "  print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and Next Steps\n",
    "\n",
    "* The dataset has been successfully downloaded from Kaggle and saved.\n",
    "* Next step: **02 - JobMarketStudy** — Exploratory Data Analysis and correlation study."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
